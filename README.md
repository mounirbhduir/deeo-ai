# DEEO.AI - Proof of Concept

[![Tests](https://img.shields.io/badge/tests-178%2F178%20passing-brightgreen)]()
[![Coverage](https://img.shields.io/badge/coverage-68--94%25-green)]()
[![Python](https://img.shields.io/badge/python-3.11+-blue)]()
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104-009688)]()
[![PostgreSQL](https://img.shields.io/badge/PostgreSQL-15.5-336791)]()
[![Redis](https://img.shields.io/badge/Redis-7.0-DC382D)]()

**AI Dynamic Emergence and Evolution Observatory**

Open source observatory for tracking and analyzing AI technologies, publications, and actors.

---

## ğŸ¯ Phase 2 Complete âœ…

**Phase 2 - ModÃ¨les SQLAlchemy + API CRUD** est maintenant **100% complÃ©tÃ©e** !

### Accomplissements Phase 2

- âœ… **31 modÃ¨les SQLAlchemy** crÃ©Ã©s (14 entitÃ©s + 17 associations)
- âœ… **29 tables PostgreSQL** migrÃ©es avec Alembic
- âœ… **6 repositories** avec Data Access Layer (94% coverage)
- âœ… **5 services** avec Business Logic (86% coverage)
- âœ… **24 schÃ©mas Pydantic** avec validation
- âœ… **6 routers FastAPI** avec 27 endpoints REST
- âœ… **178 tests passing** (100% success rate) ğŸ†
- âœ… **Coverage 68-94%** selon layer
- âœ… **Swagger UI** auto-documentÃ©e
- âœ… **Architecture Layered** complÃ¨te

**Prochaine Ã©tape** : Phase 3 - Pipeline ETL + ML Classification ğŸš€

---

## ğŸš€ Quick Start - Phase 2

### Prerequisites

- Python 3.11+
- Docker & Docker Compose
- Git

### Installation

1. **Clone repository**
```bash
git clone <repository-url>
cd deeo-ai-poc
```

2. **Configure environment**
```bash
cp .env.example .env
# Edit .env with your configuration
```

3. **Start services**
```bash
docker-compose up -d
```

4. **Run database migrations**
```bash
docker-compose exec api alembic upgrade head
```

5. **Verify services**
```bash
# Check PostgreSQL
docker-compose exec postgres pg_isready -U deeo_user

# Check Redis
docker-compose exec redis redis-cli ping

# Check API
curl http://localhost:8000/api/health
```

6. **Access API documentation**
   - Swagger UI: http://localhost:8000/api/docs
   - ReDoc: http://localhost:8000/api/redoc

---

## ğŸ“š API Endpoints (Phase 2)

### Health & Status
- `GET /` - Root endpoint
- `GET /api/health` - Health check (database + Redis)
- `GET /api/version` - API version

### Publications
- `GET /api/v1/publications` - List publications (pagination)
- `GET /api/v1/publications/{id}` - Get publication by ID
- `POST /api/v1/publications` - Create publication
- `PUT /api/v1/publications/{id}` - Update publication
- `DELETE /api/v1/publications/{id}` - Delete publication

### Auteurs
- `GET /api/v1/auteurs` - List authors (pagination)
- `GET /api/v1/auteurs/{id}` - Get author by ID
- `POST /api/v1/auteurs` - Create author
- `PUT /api/v1/auteurs/{id}` - Update author
- `DELETE /api/v1/auteurs/{id}` - Delete author

### Organisations
- `GET /api/v1/organisations` - List organizations (pagination)
- `GET /api/v1/organisations/{id}` - Get organization by ID
- `POST /api/v1/organisations` - Create organization
- `PUT /api/v1/organisations/{id}` - Update organization
- `DELETE /api/v1/organisations/{id}` - Delete organization

### Themes
- `GET /api/v1/themes` - List themes (pagination)
- `GET /api/v1/themes/{id}` - Get theme by ID
- `POST /api/v1/themes` - Create theme
- `PUT /api/v1/themes/{id}` - Update theme
- `DELETE /api/v1/themes/{id}` - Delete theme

### Datasets
- `GET /api/v1/datasets` - List datasets (pagination)
- `GET /api/v1/datasets/{id}` - Get dataset by ID
- `POST /api/v1/datasets` - Create dataset
- `PUT /api/v1/datasets/{id}` - Update dataset
- `DELETE /api/v1/datasets/{id}` - Delete dataset

### API Examples

**List publications with pagination:**
```bash
curl "http://localhost:8000/api/v1/publications?skip=0&limit=10"
```

**Get publication by ID:**
```bash
curl "http://localhost:8000/api/v1/publications/{uuid}"
```

**Create publication:**
```bash
curl -X POST "http://localhost:8000/api/v1/publications" \
  -H "Content-Type: application/json" \
  -d '{
    "titre": "Deep Learning for AI Research",
    "abstract": "A comprehensive study on deep learning techniques",
    "doi": "10.1234/example.2025",
    "arxiv_id": "arxiv:2501.12345",
    "date_publication": "2025-11-17",
    "type_publication": "article",
    "status": "pending_enrichment"
  }'
```

**Update publication:**
```bash
curl -X PUT "http://localhost:8000/api/v1/publications/{uuid}" \
  -H "Content-Type: application/json" \
  -d '{
    "status": "enriched",
    "metadata_": {"citations_count": 42}
  }'
```

**Delete publication:**
```bash
curl -X DELETE "http://localhost:8000/api/v1/publications/{uuid}"
```

---

## ğŸ—ï¸ Project Structure (Phase 2)

```
deeo-ai-poc/
â”œâ”€â”€ backend/                    # FastAPI application
â”‚   â”œâ”€â”€ app/                   # Application code
â”‚   â”‚   â”œâ”€â”€ models/           # 31 SQLAlchemy models
â”‚   â”‚   â”œâ”€â”€ repositories/     # 6 repositories (Data Access Layer)
â”‚   â”‚   â”œâ”€â”€ services/         # 5 services (Business Logic)
â”‚   â”‚   â”œâ”€â”€ schemas/          # 24 Pydantic schemas
â”‚   â”‚   â”œâ”€â”€ api/              # 6 FastAPI routers
â”‚   â”‚   â”‚   â””â”€â”€ v1/          # API v1 endpoints
â”‚   â”‚   â”œâ”€â”€ core/            # Core utilities
â”‚   â”‚   â”œâ”€â”€ config.py        # Configuration
â”‚   â”‚   â”œâ”€â”€ database.py      # Database setup
â”‚   â”‚   â””â”€â”€ main.py          # FastAPI app
â”‚   â”œâ”€â”€ alembic/             # Database migrations
â”‚   â”œâ”€â”€ tests/               # 178 tests (100% passing)
â”‚   â”‚   â”œâ”€â”€ repositories/   # 62 tests (94% coverage)
â”‚   â”‚   â”œâ”€â”€ services/       # 46 tests (86% coverage)
â”‚   â”‚   â””â”€â”€ api/            # 70 tests (68% coverage)
â”‚   â”œâ”€â”€ Dockerfile           # Docker image
â”‚   â”œâ”€â”€ requirements.txt     # Python dependencies
â”‚   â”œâ”€â”€ pytest.ini          # pytest configuration
â”‚   â””â”€â”€ conftest.py         # Test fixtures
â”œâ”€â”€ docs/                     # Documentation
â”‚   â”œâ”€â”€ ARCHITECTURE.md      # Architecture technique
â”‚   â”œâ”€â”€ MEMORY_BANK_PHASE_2_FINAL.md
â”‚   â”œâ”€â”€ RAPPORT_PHASE_2_COMPLETE.md
â”‚   â””â”€â”€ context/            # Project context
â”œâ”€â”€ frontend/                # React application (Phase 4)
â”œâ”€â”€ tests/                   # Additional tests
â”œâ”€â”€ scripts/                 # Utility scripts
â”œâ”€â”€ docker-compose.yml       # Services orchestration
â”œâ”€â”€ .env.example             # Environment template
â””â”€â”€ README.md                # This file
```

---

## ğŸ“Š Test Coverage (Phase 2)

| Layer | Tests | Coverage | Status |
|-------|-------|----------|--------|
| **Repositories** | 62 | 94% | âœ… Excellent |
| **Services** | 46 | 86% | âœ… TrÃ¨s bon |
| **API** | 70 | 68-74% | âœ… Bon |
| **Total** | **178** | **68-94%** | âœ… Solide |

**Run tests:**
```bash
# All tests
docker-compose exec api pytest tests/ -v

# With coverage
docker-compose exec api pytest tests/ --cov=app --cov-report=term-missing

# Coverage HTML report
docker-compose exec api pytest tests/ --cov=app --cov-report=html
# Open: backend/htmlcov/index.html

# Specific layer
docker-compose exec api pytest tests/repositories/ -v
docker-compose exec api pytest tests/services/ -v
docker-compose exec api pytest tests/api/ -v
```

---

## ğŸ§ª Development

### Run tests
```bash
docker-compose exec api pytest -v
docker-compose exec api pytest --cov=app --cov-report=html
```

### Code quality
```bash
# Formatting
docker-compose exec api black app/

# Linting
docker-compose exec api pylint app/
```

### Database migrations
```bash
# Create migration
docker-compose exec api alembic revision --autogenerate -m "description"

# Apply migrations
docker-compose exec api alembic upgrade head

# Rollback migration
docker-compose exec api alembic downgrade -1

# Migration history
docker-compose exec api alembic history
```

### Database access
```bash
# PostgreSQL shell
docker-compose exec postgres psql -U deeo_user -d deeo_ai

# List tables
docker-compose exec postgres psql -U deeo_user -d deeo_ai -c '\dt'

# View table structure
docker-compose exec postgres psql -U deeo_user -d deeo_ai -c '\d+ publication'

# Redis CLI
docker-compose exec redis redis-cli
```

---

## ğŸ› ï¸ Tech Stack

### Backend
- **Python** 3.11+ - Language with type hints, async/await
- **FastAPI** 0.104+ - Modern async web framework
- **SQLAlchemy** 2.0 - Async ORM with PostgreSQL
- **Alembic** 1.12+ - Database migrations
- **Pydantic** 2.0+ - Data validation and schemas
- **pytest** 7.4+ - Testing framework with pytest-asyncio

### Infrastructure
- **PostgreSQL** 15.5 - Main database (29 tables)
- **Redis** 7.0 - Cache and sessions
- **Docker** - Containerization
- **Docker Compose** - Services orchestration

### Development Tools
- **Git** - Version control
- **Claude Code** - AI-powered development assistant

---

## ğŸ“– Documentation

- [Architecture](docs/ARCHITECTURE.md) - Technical architecture details
- [Memory Bank Phase 2](docs/MEMORY_BANK_PHASE_2_FINAL.md) - Phase 2 complete state
- [Phase 2 Report](docs/RAPPORT_PHASE_2_COMPLETE.md) - Detailed Phase 2 report
- [API Documentation](http://localhost:8000/api/docs) - Swagger UI (when running)

---

## ğŸ¯ Next Steps - Phase 3

**Phase 3 - Pipeline ETL + ML Classification** (Upcoming)

### Planned Features
1. **ArxivCollector** - Daily pipeline to collect publications from arXiv API
2. **SemanticScholarEnricher** - Hourly enrichment with citations, h-index, author metrics
3. **ZeroShotClassifier** - Multi-label theme classification with BART model
4. **EmbeddingsExtractor** - Semantic search with Sentence-Transformers
5. **APScheduler** - Job orchestration (daily, hourly, weekly jobs)
6. **Redis Cache** - Advanced caching with differentiated TTLs
7. **Monitoring** - Structured logs, job tracking, performance metrics
8. **Documentation** - ETL pipeline guides, configuration docs

### Expected Volumes
- 15,000-25,000 publications
- 10,000-20,000 authors
- 2,000-5,000 organizations
- 50-100 active themes
- 50,000-100,000 classifications

---

## âœ… Project Status

### Phase 1 - Infrastructure âœ… **COMPLETE**
- âœ… Docker Compose (PostgreSQL + Redis + FastAPI)
- âœ… FastAPI skeleton with health endpoints
- âœ… Alembic migrations configured
- âœ… Initial tests passing (79% coverage)

### Phase 2 - Backend + API âœ… **COMPLETE**
- âœ… 31 SQLAlchemy models + 29 PostgreSQL tables
- âœ… 6 repositories (94% coverage)
- âœ… 5 services (86% coverage)
- âœ… 24 Pydantic schemas
- âœ… 6 FastAPI routers + 27 REST endpoints
- âœ… 178 tests passing (100% success rate)
- âœ… Swagger UI documentation

### Phase 3 - ETL Pipeline + ML ğŸ”„ **UPCOMING**
- [ ] ArxivCollector pipeline
- [ ] SemanticScholar enrichment
- [ ] ZeroShot classification
- [ ] Embeddings extraction
- [ ] APScheduler jobs
- [ ] Redis cache advanced
- [ ] Tests â‰¥80% coverage

### Phase 4 - Frontend + Deployment ğŸ“… **PLANNED**
- [ ] React 18 + TypeScript frontend
- [ ] Interactive visualizations
- [ ] User authentication
- [ ] Production deployment

---

## ğŸ“ License

MIT License - See LICENSE file

---

## ğŸ‘¥ Authors

**Mounir** - Master Big Data & IA - UniversitÃ© Internationale de Rabat (UIR)

---

## ğŸ™ Acknowledgments

- Developed with assistance from **Claude Code** (Anthropic)
- Phase 2 completed with "Claude Code First" workflow (91% time gain)

---

**Version**: 2.0.0 (Phase 2 - Backend Complete)
**Last Updated**: November 17, 2025
**Status**: âœ… Phase 2 Complete - Ready for Phase 3
