# ğŸ“‹ Guide d'Utilisation - Script `populate_real_data.py`

## ğŸ“– Description

Script automatique de peuplement de la base de donnÃ©es STAGING avec des **donnÃ©es rÃ©elles** collectÃ©es depuis arXiv.

### FonctionnalitÃ©s

- âœ… **Collecte automatique** de publications depuis arXiv (catÃ©gories IA)
- âœ… **Pipeline ETL complet** : Extract, Transform, Load
- âœ… **DÃ©duplication** : Ã‰vite les doublons
- âœ… **Gestion relations** : Auteurs, thÃ¨mes, organisations
- âœ… **Logs dÃ©taillÃ©s** : Progression en temps rÃ©el
- âœ… **Statistiques complÃ¨tes** : Bilan final de la collecte

### CatÃ©gories CollectÃ©es

- `cs.AI` - Artificial Intelligence
- `cs.LG` - Machine Learning
- `cs.CV` - Computer Vision
- `cs.CL` - Computation and Language
- `cs.NE` - Neural and Evolutionary Computing
- `stat.ML` - Machine Learning (Statistics)

---

## ğŸš€ Utilisation

### 1. Depuis l'HÃ´te (via Docker Compose)

```bash
# Collecte standard (15,000 publications)
docker-compose -f docker-compose.staging.yml exec api python scripts/populate_real_data.py

# Collecte limitÃ©e pour test (500 publications)
docker-compose -f docker-compose.staging.yml exec api python scripts/populate_real_data.py --max-publications 500

# Avec batch size personnalisÃ©
docker-compose -f docker-compose.staging.yml exec api python scripts/populate_real_data.py --max-publications 10000 --batch-size 50

# Sur 6 mois seulement
docker-compose -f docker-compose.staging.yml exec api python scripts/populate_real_data.py --date-range-months 6
```

### 2. Depuis le Conteneur

```bash
# Entrer dans le conteneur
docker-compose -f docker-compose.staging.yml exec api bash

# ExÃ©cuter le script
python scripts/populate_real_data.py --max-publications 1000
```

---

## âš™ï¸ Options

| Option | Type | DÃ©faut | Description |
|--------|------|--------|-------------|
| `--max-publications` | int | 15000 | Nombre maximum de publications Ã  collecter |
| `--batch-size` | int | 100 | Taille des batchs pour requÃªtes arXiv |
| `--date-range-months` | int | 24 | Nombre de mois en arriÃ¨re (2 ans par dÃ©faut) |

---

## ğŸ“Š Exemple de Sortie

```
================================================================================
ğŸš€ DÃ‰MARRAGE PEUPLEMENT STAGING AVEC DONNÃ‰ES RÃ‰ELLES
================================================================================
Configuration:
  - Max publications: 15000
  - Batch size: 100
  - Date range: 2023-11-20 to 2025-11-20
  - Categories: cs.AI, cs.LG, cs.CV, cs.CL, cs.NE, stat.ML

================================================================================
ğŸ“¥ Ã‰TAPE 1/2 : COLLECTE PUBLICATIONS ARXIV
================================================================================

[1/8] ğŸ” RequÃªte: 'deep learning'
  âœ… CollectÃ©es: 187
  â• CrÃ©Ã©es: 178
  ğŸ”„ Mises Ã  jour: 5
  â­ï¸  IgnorÃ©es: 4
  ğŸ‘¥ Auteurs: 456
  ğŸ·ï¸  ThÃ¨mes: 12

[2/8] ğŸ” RequÃªte: 'neural networks'
  âœ… CollectÃ©es: 165
  â• CrÃ©Ã©es: 152
  ...

================================================================================
ğŸ¤– Ã‰TAPE 2/2 : CLASSIFICATION ML THÃ‰MATIQUE
================================================================================
â„¹ï¸  Les thÃ¨mes ont dÃ©jÃ  Ã©tÃ© assignÃ©s par le pipeline arXiv
âœ… Ã‰tape de classification complÃ©tÃ©e

================================================================================
ğŸ“Š STATISTIQUES FINALES
================================================================================

ğŸ“š DONNÃ‰ES DANS LA BASE :
    Publications    : 1523
    Auteurs         : 3891
    ThÃ¨mes          : 47

ğŸ“Š OPÃ‰RATIONS EFFECTUÃ‰ES :
    CollectÃ©es      : 1587
    CrÃ©Ã©es          : 1523
    Mises Ã  jour    : 32
    IgnorÃ©es        : 32
    Nouveaux auteurs: 3891
    Nouveaux thÃ¨mes : 47

âœ… Aucune erreur

ğŸ¯ STATISTIQUES PAR REQUÃŠTE :
    'deep learning':
      - CollectÃ©es : 187
      - CrÃ©Ã©es     : 178
      - DurÃ©e      : 45.2s
    ...

================================================================================
âœ… PEUPLEMENT TERMINÃ‰ EN 0:12:34
================================================================================
```

---

## ğŸ”§ Architecture Technique

### Pipeline ETL

Le script utilise `ArxivPipeline` qui orchestre :

1. **Extract** : Collecte depuis arXiv API avec rate limiting
2. **Transform** : Mappage vers modÃ¨les de base de donnÃ©es
3. **Load** : Insertion avec dÃ©duplication

### Composants UtilisÃ©s

```python
app/pipelines/
â”œâ”€â”€ arxiv_collector.py      # Collection arXiv avec retry logic
â”œâ”€â”€ arxiv_pipeline.py        # Orchestrateur ETL complet
â”œâ”€â”€ arxiv_mappers.py         # Transformation donnÃ©es
â”œâ”€â”€ deduplication.py         # Gestion doublons
â””â”€â”€ ml_classifier.py         # Classification thÃ©matique
```

### Gestion Erreurs

- **Rate limiting** : Respect des limites arXiv (1 req/3s)
- **Retry automatique** : 3 tentatives avec backoff exponentiel
- **Skip gracieux** : Continue en cas d'erreur sur une publication
- **Logs dÃ©taillÃ©s** : Toutes les erreurs sont logguÃ©es

---

## ğŸ› Troubleshooting

### Erreur : "No such file or directory"

```bash
# VÃ©rifier que le script existe
docker-compose -f docker-compose.staging.yml exec api ls -la scripts/

# Si absent, recrÃ©er le script
# (uploader depuis l'hÃ´te ou recrÃ©er dans le conteneur)
```

### Erreur : "Module 'app' not found"

```bash
# Le script doit Ãªtre exÃ©cutÃ© depuis /app dans le conteneur
docker-compose -f docker-compose.staging.yml exec api bash
cd /app
python scripts/populate_real_data.py
```

### Erreur : "Connection refused" (PostgreSQL)

```bash
# VÃ©rifier que PostgreSQL est UP
docker-compose -f docker-compose.staging.yml ps

# VÃ©rifier les variables d'environnement
docker-compose -f docker-compose.staging.yml exec api env | grep DATABASE
```

### Performances Lentes

```bash
# RÃ©duire le nombre de publications pour test
python scripts/populate_real_data.py --max-publications 500

# Augmenter le batch size (attention au rate limit)
python scripts/populate_real_data.py --batch-size 50
```

### Interruption (Ctrl+C)

Le script gÃ¨re gracieusement les interruptions. Les publications dÃ©jÃ  insÃ©rÃ©es restent en base grÃ¢ce aux commits transactionnels.

---

## ğŸ“ˆ Monitoring

### VÃ©rifier Progression en Base

```bash
# Depuis l'hÃ´te
docker-compose -f docker-compose.staging.yml exec postgres psql -U deeo_user -d deeo_ai_staging -c "SELECT COUNT(*) FROM publications;"

# Nombre d'auteurs
docker-compose -f docker-compose.staging.yml exec postgres psql -U deeo_user -d deeo_ai_staging -c "SELECT COUNT(*) FROM auteurs;"

# ThÃ¨mes crÃ©Ã©s
docker-compose -f docker-compose.staging.yml exec postgres psql -U deeo_user -d deeo_ai_staging -c "SELECT label, COUNT(*) as nb FROM themes GROUP BY label ORDER BY nb DESC LIMIT 10;"
```

### Logs en Temps RÃ©el

```bash
# Suivre les logs du conteneur API
docker-compose -f docker-compose.staging.yml logs -f api
```

---

## ğŸ”„ RÃ©initialisation

Pour effacer les donnÃ©es et recommencer :

```bash
# Entrer dans PostgreSQL
docker-compose -f docker-compose.staging.yml exec postgres psql -U deeo_user -d deeo_ai_staging

# Truncate tables (dans psql)
TRUNCATE TABLE publications CASCADE;
TRUNCATE TABLE auteurs CASCADE;
TRUNCATE TABLE themes CASCADE;
```

**âš ï¸ Attention** : `CASCADE` supprime aussi les relations (publication_auteurs, publication_themes, etc.)

---

## ğŸ“ Notes Importantes

### Rate Limiting arXiv

L'API arXiv limite Ã  **1 requÃªte par 3 secondes**. Le script respecte cette limite automatiquement avec `aiolimiter`.

### Temps d'ExÃ©cution EstimÃ©

- **500 publications** : ~3-5 minutes
- **5,000 publications** : ~30-45 minutes
- **15,000 publications** : ~1.5-2 heures

Le temps varie selon :
- La charge de l'API arXiv
- La vitesse rÃ©seau
- Le nombre d'auteurs/thÃ¨mes nouveaux

### Semantic Scholar

L'enrichissement Semantic Scholar (citations, h-index) n'est **pas encore implÃ©mentÃ©** dans ce script. Il sera ajoutÃ© dans une version ultÃ©rieure avec `semantic_scholar_enricher.py`.

---

## âœ… Checklist Post-ExÃ©cution

- [ ] VÃ©rifier nombre de publications en base
- [ ] VÃ©rifier que les relations auteurs sont crÃ©Ã©es
- [ ] VÃ©rifier que les thÃ¨mes sont assignÃ©s
- [ ] Tester l'API frontend (`/api/v1/publications`)
- [ ] VÃ©rifier logs pour erreurs Ã©ventuelles
- [ ] Backup de la base (optionnel)

---

**CrÃ©Ã© le** : 20 novembre 2025
**Version** : 1.0.0
**Auteur** : Claude Code Assistant
